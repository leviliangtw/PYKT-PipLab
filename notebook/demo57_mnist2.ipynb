{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import datasets, utils, layers, Sequential\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image shape=(60000, 28, 28), test image shape=(10000, 28, 28)\n",
      "train label shape=(60000,), test label shape=(10000,)\n",
      "after flatten, train image shape=(60000, 784), test image shape=(10000, 784)\n",
      "NUM_DIGITS=10\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 218,058\n",
      "Trainable params: 218,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "print(f\"train image shape={train_images.shape}, test image shape={test_images.shape}\")\n",
    "print(f\"train label shape={train_labels.shape}, test label shape={test_labels.shape}\")\n",
    "# print(matplotlib.get_backend())\n",
    "\n",
    "flatten = 28 * 28\n",
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "# print(TRAINING_SIZE, TEST_SIZE)\n",
    "trainImages = np.reshape(train_images, (TRAINING_SIZE, flatten))\n",
    "testImages = np.reshape(test_images, (TEST_SIZE, flatten))\n",
    "print(f\"after flatten, train image shape={trainImages.shape}, test image shape={testImages.shape}\")\n",
    "\n",
    "# convert to float\n",
    "trainImages = trainImages.astype(np.float32)\n",
    "testImages = testImages.astype(np.float32)\n",
    "# print(trainImages[0])\n",
    "trainImages /= 255\n",
    "testImages /= 255\n",
    "# print(trainImages[0])\n",
    "\n",
    "NUM_DIGITS = len(np.unique(train_labels))\n",
    "print(f'NUM_DIGITS={NUM_DIGITS}')\n",
    "trainLabels = utils.to_categorical(train_labels, NUM_DIGITS)\n",
    "testILabels = utils.to_categorical(test_labels, NUM_DIGITS)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(256, activation=tf.nn.relu, input_shape=(flatten,)))\n",
    "model.add(layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(layers.Dense(10, activation=tf.nn.softmax))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallback = TensorBoard(log_dir='../log', histogram_freq=True,\n",
    "                         write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2144 - accuracy: 0.9369\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0953 - accuracy: 0.9719\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0731 - accuracy: 0.9795\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0575 - accuracy: 0.9848\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0485 - accuracy: 0.9865\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0405 - accuracy: 0.9890\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0343 - accuracy: 0.9908\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0330 - accuracy: 0.9918\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0265 - accuracy: 0.9930\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0249 - accuracy: 0.9937\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0220 - accuracy: 0.9942\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0201 - accuracy: 0.9950\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0154 - accuracy: 0.9958\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0173 - accuracy: 0.9958\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0139 - accuracy: 0.9964\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0137 - accuracy: 0.9965\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0116 - accuracy: 0.9970\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0109 - accuracy: 0.9971\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0103 - accuracy: 0.9975\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0099 - accuracy: 0.9973\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainImages, trainLabels, epochs=20, callbacks=[tbCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test marker as: [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "predict as: [[0.0000000e+00 0.0000000e+00 1.1869781e-28 4.4912720e-23 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 1.4972663e-37 2.0959193e-26]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 5.2443340e-34 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [7.9092449e-28 1.0000000e+00 1.2860488e-13 2.3166024e-18 7.9969336e-14\n",
      "  5.8185011e-13 9.3789536e-15 3.2359924e-11 1.1709390e-12 1.0609890e-20]\n",
      " [1.0000000e+00 2.0426805e-32 1.0943064e-18 2.0154024e-19 4.5623499e-22\n",
      "  1.8100234e-19 4.3925248e-15 1.2279282e-18 9.7572864e-24 3.1936221e-15]\n",
      " [4.0426419e-26 4.8781018e-35 3.3783017e-22 2.3257946e-32 1.0000000e+00\n",
      "  5.5256726e-28 1.5328330e-20 1.0078008e-15 4.7412636e-25 8.0112342e-15]\n",
      " [2.2369554e-28 1.0000000e+00 4.5161926e-19 2.4442878e-21 1.8290237e-12\n",
      "  1.4073434e-18 2.7069689e-17 1.3621320e-12 8.5093181e-17 1.5165469e-21]\n",
      " [0.0000000e+00 4.8497941e-25 1.4941153e-24 1.0751942e-24 1.0000000e+00\n",
      "  6.1821128e-28 3.9526594e-32 8.9186852e-15 1.4282270e-15 8.3794947e-19]\n",
      " [2.4433391e-25 1.6880906e-20 1.6183750e-13 1.9757766e-02 1.2958302e-13\n",
      "  6.6421776e-14 8.5044797e-31 4.3132973e-09 4.4366340e-11 9.8024219e-01]\n",
      " [0.0000000e+00 0.0000000e+00 3.2409176e-28 3.3437444e-28 5.6774272e-29\n",
      "  9.8393875e-01 1.6061310e-02 0.0000000e+00 8.3165433e-21 5.0576114e-28]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8061067e-33 1.1402099e-11\n",
      "  2.1025692e-38 0.0000000e+00 8.6438503e-24 5.0248360e-27 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "predictLabels = model.predict(testImages)\n",
    "print(f\"test marker as: {testILabels[:10]}\")\n",
    "print(f\"predict as: {predictLabels[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 25us/step\n",
      "test loss=0.20159224009921264, test accuracy=0.9804999828338623\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(testImages, testILabels)\n",
    "print(f'test loss={loss}, test accuracy={accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
